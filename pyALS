#!/usr/bin/python3
"""
Copyright 2021-2022 Salvatore Barone <salvatore.barone@unina.it>

This is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 3 of the License, or any later version.

This is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for
more details.

You should have received a copy of the GNU General Public License along with
RMEncoder; if not, write to the Free Software Foundation, Inc., 51 Franklin
Street, Fifth Floor, Boston, MA 02110-1301, USA.
"""

import sys, os, click, configparser, git
from pyosys import libyosys as ys
from distutils.dir_util import mkpath
from src.ALSCatalog import *
from src.MOP import *
from src.ALSRewriter import *
from src.stats import *


def git_updater():
	repo = git.Repo('.')
	repo.remotes.origin.fetch()
	local_head = repo.heads[0].commit
	remote_head = repo.remotes.origin.refs[0].commit
	if remote_head != local_head:
		print("Updating the tool...")
		repo.remotes.origin.pull()
		for submodule in repo.submodules:
			submodule.update(init = True, recursive = True)
		return True
	return False


def read_source(source_file, top_module, ys_design):
	name, extension = os.path.splitext(source_file)
	if extension == ".vhd":
		ys.run_pass(f"ghdl {source_file} -e {top_module}", ys_design)
	elif extension == ".sv":
		ys.run_pass(f"read_verilog -sv {source_file}", ys_design)
	elif extension == ".v":
		ys.run_pass(f"read_verilog {source_file}", ys_design)
	elif extension == ".blif":
		ys.run_pass(f"read_blif {source_file}", ys_design)
	ys.run_pass(f"hierarchy -check -top {top_module}", ys_design)


def synth_design(ys_design, top_module, cut_size, design_name_save="original"):
	ys.run_pass(f"prep; flatten; splitnets -ports; synth -top {top_module}; flatten; clean -purge; synth -lut {str(cut_size)}", ys_design)
	ys.run_pass(f"tee -q design -save {design_name_save}", ys_design)


def config_parser(config_file):
	config = configparser.ConfigParser(converters={'list': lambda x: [i.strip() for i in x.split(',')]})
	config.read(config_file)
	try:
		als_conf = ALSConfig(
			config["als"]["cut_size"] if "cut_size" in config["als"] else "4",
			config["als"]["solver"] if "solver" in config["als"] else "boolector",
			int(config["als"]["timeout"]) if "timeout" in config["als"] else 60000)
		error_conf = ErrorConfig(
			config["error"]["metric"] if "metric" in config["error"] else "eprob",
			float(config["error"]["threshold"]) if "threshold" in config["error"] else .5,
			int(config["error"]["vectors"] if "vectors" in config["error"] else 1000))
		hw_conf = HwConfig(
			list(map(str, config.getlist('hardware', 'metric'))) if "metric" in config["hardware"] else ["gates"])
		amosa_conf = AMOSAConfig(
			int(config["amosa"]["archive_hard_limit"]) if "archive_hard_limit" in config["amosa"] else 50,
			int(config["amosa"]["archive_soft_limit"]) if "archive_soft_limit" in config["amosa"] else 100,
			int(config["amosa"]["archive_gamma"]) if "archive_gamma" in config["amosa"] else 3,
			int(config["amosa"]["hill_climbing_iterations"]) if "hill_climbing_iterations" in config["amosa"] else 100,
			float(config["amosa"]["initial_temperature"]) if "initial_temperature" in config["amosa"] else 500,
			float(config["amosa"]["final_temperature"]) if "final_temperature" in config["amosa"] else 0.0000001,
			float(config["amosa"]["cooling_factor"]) if "cooling_factor" in config["amosa"] else 0.8,
			int(config["amosa"]["annealing_iterations"]) if "annealing_iterations" in config["amosa"] else 100,
			int(config["amosa"]["annealing_strength"]) if "annealing_strength" in config["amosa"] else 1,
			int(config["amosa"]["early_termination"]) if "early_termination" in config["amosa"] else 20)
		return als_conf, error_conf, hw_conf, amosa_conf
	except KeyError as e:
		print(f"no {e} in {config_file}")
		exit()


def weights_parser(weights_file, graph):
	with open(weights_file, "r") as file:
		raw_data = file.readlines()
	raw_data = "".join(raw_data)
	weights = eval(raw_data)
	po_names = [o["name"] for o in graph.get_po()]
	for k in weights.keys():
		if k not in po_names:
			graph.plot()
			raise ValueError(f"{k} not found in POs {po_names}")
	return weights


def plot_labels(error_conf, hw_conf):
	error_labels = {
		ErrorConfig.Metric.EPROB : "Error probability",
		ErrorConfig.Metric.AWCE : "AWCE",
		ErrorConfig.Metric.MED : "MED"
	}
	hw_labels = {
		HwConfig.Metric.GATES : "#AIG nodes",
		HwConfig.Metric.DEPTH : "AIG depth",
		HwConfig.Metric.SWITCHING : "Switching activity"
	}
	return [ error_labels[error_conf.metric] ] + [ hw_labels[m] for m in hw_conf.metrics ]


@click.group()
def cli():
	pass


@click.command('clean')
@click.option('--catalog', type = str, required = True, help = 'Path of the LUT-catalog cache file')
def clean(catalog):
	"""Performs a sanity check of the catalog """
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	cache = ALSCatalogCache(catalog)
	count = 0
	for s in cache.get_all_exact_luts():
		exact_synth_spec, exact_S, exact_P, exact_out_p, exact_out, exact_depth = s
		gates = len(exact_S[0])
		distance = 0
		for spec in cache.get_approx_luts(exact_synth_spec):
			ax_synth_spec, ax_S, ax_P, ax_out_p, ax_out, ax_depth = spec
			dist = hamming(exact_synth_spec, ax_synth_spec)
			if len(ax_S[0]) >= gates or dist < distance:
				cache.del_lut(exact_synth_spec, dist)
				count += 1
			else:
				gates = len(ax_S[0])
				distance = dist
	# search for complemented specifications
	for x in cache.get_all_exact_luts():
		x_synth_spec, _, _, _, _, _ = x
		for y in cache.get_all_exact_luts():
			y_synth_spec, _, _, _, _, _ = y
			if x_synth_spec == negate(y_synth_spec):
				cache.del_spec(y_synth_spec)
				count += 1
	print(f"Deleted {count} instances")


@click.command("expand")
@click.option('--catalog', type = str, required = True, help = 'Path of the LUT-catalog cache file')
def expand(catalog):
	""" Attempts catalog expansion """
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	cache = ALSCatalogCache(catalog)

	# try to complete any incomplete path in the catalog
	luts_to_be_synthesized = set()
	for x in cache.get_all_exact_luts():
		ex_spec, ex_dist, ex_synth_spec, ex_S, ex_P, ex_p, ex_out, ex_depth = x
		axspect = cache.get_approx_luts(ex_spec)
		ax_synth_spec, ax_S, ax_P, ax_out_p, ax_out, ax_depth = axspect[-1]
		gates = len(ax_S[0])
		distance = hamming(ex_spec, ax_synth_spec)
		if gates > 0:
			print(f"Incomplete catalog found for spec {ex_spec}. Synthesis will start from Hamming distance {distance + 1}")
			luts_to_be_synthesized.add((ex_spec, gates, distance + 1))
	luts_to_be_synthesized = list(luts_to_be_synthesized)
	random.shuffle(luts_to_be_synthesized)
	luts_sets = list_partitioning(luts_to_be_synthesized, cpu_count())
	args = [[catalog, lut_set, 60000, ALSConfig.Solver.Boolector] for lut_set in luts_sets]
	with Pool(cpu_count()) as pool:
		ax_added = pool.starmap(synthesize_at_dist, args)
	print(f"{sum(ax_added)} new approximate LUTs inserted in the catalog cache while attempting catalog completion")


	# for each lut in the catalog, we add the synthesized approximate lut as exact lut at distance 0, if they do not belong to the catalog
	# this improves the hit-rate for exact luts
	exact_added = 0
	luts_to_be_synthesized = set()
	for x in cache.get_all_luts():
		x_spec, x_dist, x_synth_spec, x_S, x_P, x_p, x_out, x_depth = x
		if cache.get_lut_at_dist(x_synth_spec, 0) is None:
			cache.add_lut(x_synth_spec, 0, x_synth_spec, x_S, x_P, x_p, x_out, x_depth)
			if x_synth_spec not in luts_to_be_synthesized and negate(x_synth_spec) not in luts_to_be_synthesized:
				luts_to_be_synthesized.add(x_synth_spec)
			exact_added += 1
	print(f"{exact_added} new exact LUTs inserted in the catalog cache")

	luts_to_be_synthesized = list(luts_to_be_synthesized)
	random.shuffle(luts_to_be_synthesized)
	luts_sets = list_partitioning(luts_to_be_synthesized, cpu_count())
	args = [[catalog, lut_set, 60000, ALSConfig.Solver.Boolector] for lut_set in luts_sets]
	with Pool(cpu_count()) as pool:
		ax_added = pool.starmap(synthesize, args)
	print(f"{sum(ax_added)} new approximate LUTs inserted in the catalog cache")


@click.command("plot")
@click.option("--source",  type=str, required=True, help="specify the input HDL source file")
@click.option("--top",     type=str, required=True, help="specify the top-module name")
@click.option("--lut",     type=str, required=True, help="specify the LUT size")
@click.option("--output",  type=str, required=True, help="Output file.")
def plot(source, top, lut, output):
	"""
	Draws a k-LUT map of the given circuit
	"""
	if not os.path.exists(source):
		print(f"{source}: no such file.")
		exit()
	design = ys.Design()
	ys.run_pass("plugin -i ghdl", design)
	print("GHDL plugin loaded successfully")
	read_source(source, top, design)
	print(f"{source} read successfully")
	synth_design(design, top, lut)
	print(f"{lut}-LUT synthesis successful")
	graph = ALSGraph(design)
	print(f"Graph generation completed")
	graph.save(output)


@click.command("es")
@click.option("--source",  type=str, required=True, help="specify the input HDL source file")
@click.option("--top",     type=str, required=True, help="specify the top-module name ")
@click.option("--catalog", type=str,                help = "specify the path for the LUT-catalog cache file", default="lut_catalog.db")
@click.option("--config",  type=str,                help="path of the configuration file", default="config.ini")
def es_synth(source, top, catalog, config):
	"""
	Performs the catalog-based AIG-rewriting workflow until catalog generation, i.e., including cut enumeration, and
	exact synthesis of approximate cuts, but it performs neither the design space exploration phase not the rewriting.
	"""
	if not os.path.exists(source):
		print(f"{source}: no such file.")
		exit()
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	if not os.path.exists(config):
		print(f"{config}: no such file.")
		exit()
	als_conf, error_conf, hw_conf, amosa_conf = config_parser(config)
	design = ys.Design()
	ys.run_pass("plugin -i ghdl", design)
	print("GHDL plugin loaded successfully")
	read_source(source, top, design)
	print(f"{source} read successfully")
	synth_design(design, top, als_conf.cut_size)
	print(f"{als_conf.cut_size}-LUT synthesis successful")
	print(f"Performing catalog generation using {cpu_count()} threads. Please wait patiently. This may take time.")
	ALSCatalog(catalog, als_conf.solver).generate_catalog(design, als_conf.timeout)
	print("Done!")


@click.command("als")
@click.option("--source",  type=str,     required=True, help="specify the input HDL source file")
@click.option("--top",     type=str,     required=True, help="specify the top-module name")
@click.option("--dataset", type=str,                    help="specify input vectors for error estimation", default=None)
@click.option("--weights", type=str,                    help="specify weights for AWCE evaluation", default=None)
@click.option("--catalog", type=str,                    help = "specify the path for the LUT-catalog cache file", default="lut_catalog.db")
@click.option("--config",  type=str,                    help="path of the configuration file", default="config.ini")
@click.option("--output",  type=str,                    help="Output directory. Everything will be placed there.", default="output/")
@click.option("--improve", type=str,                    help="Path of the file containing results from previous runs to be improved", default=None)
@click.option("--resume",  is_flag=True,                help="Resume the execution")
@click.option("--hdl",     is_flag=True,                help="Enables rewriting and HDL generation")
def als(source, top, dataset, weights, catalog, config, output, improve, resume, hdl):
	"""
	Performs the full catalog-based AIG-rewriting workflow, including cut enumeration, exact synthesis of approximate
	cuts, design space exploration and rewriting.
	"""
	if not os.path.exists(source):
		print(f"{source}: no such file.")
		exit()
	if weights is not None and not os.path.exists(weights):
		print(f"{weights}: no such file.")
		exit()
	if dataset is not None and not os.path.exists(dataset):
		print(f"{dataset}: no such file.")
		exit()
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	if not os.path.exists(config):
		print(f"{config}: no such file.")
		exit()
	if improve is not None and not os.path.exists(improve):
		print(f"{improve}: no such file.")
		exit()
	if output != ".":
		mkpath(output)
	als_conf, error_conf, hw_conf, amosa_conf = config_parser(config)
	design = ys.Design()
	ys.run_pass("plugin -i ghdl", design)
	print("GHDL plugin loaded successfully")
	read_source(source, top, design)
	print(f"{source} read successfully")
	synth_design(design, top, als_conf.cut_size)
	print(f"{als_conf.cut_size}-LUT synthesis successful")
	graph = ALSGraph(design)
	print(f"Graph generation completed")
	if error_conf.metric != ErrorConfig.Metric.EPROB:
		error_conf.weights = weights_parser(weights, graph)
		print("Output-weight parsing completed")
	print(f"Performing catalog generation using {cpu_count()} threads. Please wait patiently. This may take time.")
	lut_catalog = ALSCatalog(catalog, als_conf.solver).generate_catalog(design, als_conf.timeout)
	print(f"Performing AMOSA heuristic using {cpu_count()} threads. Please wait patiently. This may take time.")
	problem = MOP(top, graph, lut_catalog, error_conf, hw_conf, dataset)
	optimizer = AMOSA(amosa_conf)
	if not resume:
		if improve is None:
			optimizer.random_archive(problem)
		else:
			optimizer.archive_from_json(problem, improve)
		optimizer.minimize(problem, output + "/checkpoint.json")
	else:
		optimizer.minimize_from_checkpoint(problem, output + "/checkpoint.json")
	hours = int(optimizer.duration / 3600)
	minutes = int((optimizer.duration - hours * 3600) / 60)
	print(f"Took {hours} hours, {minutes} minutes")
	optimizer.save_results(problem, output + "/report.csv")
	optimizer.save_pareto_set(problem, output + "/pareto_set.csv")
	optimizer.plot_pareto(problem, output + "/pareto_front.pdf", "", plot_labels(error_conf, hw_conf))
	if hdl:
		pareto_set = optimizer.pareto_set()
		print(f"Performing AIG-rewriting.")
		rewriter = ALSRewriter(graph, lut_catalog)
		for c, n in zip(pareto_set, range(len(pareto_set))):
			rewriter.rewrite_and_save("original", c, f"{output}/variant_{n:05d}")
	print(f"All done! Take a look at {output}!")


@click.command("rewrite")
@click.option("--source",  type=str, required=True, help="specify the input HDL source file")
@click.option("--top",     type=str, required=True, help="specify the top-module name ")
@click.option("--results", type=str, required=True, help="Pareto-set resulting from previous als runs")
@click.option("--catalog", type=str,                help="specify the path for the LUT-catalog cache file", default="lut_catalog.db")
@click.option("--config",  type=str,                help="path of the configuration file", default="config.ini")
@click.option("--output",  type=str,                help="Output directory. Everything will be placed there.", default="output/")
def rewrite(source, top, results, catalog, config, output):
	"""
	Given a Pareto-set resulting from previous als runs, this command allows generating HDL implementation of
	approximate circuits.
	"""
	if not os.path.exists(source):
		print(f"{source}: no such file.")
		exit()
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	if not os.path.exists(config):
		print(f"{config}: no such file.")
		exit()
	if output != ".":
		mkpath(output)
	als_conf, error_conf, hw_conf, amosa_conf = config_parser(config)
	design = ys.Design()
	ys.run_pass("plugin -i ghdl", design)
	print("GHDL plugin loaded successfully")
	read_source(source, top, design)
	print(f"{source} read successfully")
	synth_design(design, top, als_conf.cut_size)
	print(f"{als_conf.cut_size}-LUT synthesis successful")
	graph = ALSGraph(design)
	print(f"Graph generation completed")
	print(f"Performing catalog generation using {cpu_count()} threads. Please wait patiently. This may take time.")
	lut_catalog = ALSCatalog(catalog, als_conf.solver).generate_catalog(design, als_conf.timeout)
	print(f"Performing AIG-rewriting.")
	rewriter = ALSRewriter(graph, lut_catalog)
	file = open(results, "r")
	n = 0
	for row in file:
		c = [int(r) for r in list(filter(None, row.replace("\n", "").split(";")))]
		rewriter.rewrite_and_save("original", c, f"{output}/variant_{n:05d}")
		n += 1
	print(f"All done! Take a look at {output}!")


@click.command("query")
@click.option("--catalog", type=str,  required = True, help="specify the path for the LUT-catalog cache file")
@click.option("--spec",  type=str,    required = True, help="LUT specification to search")
@click.option("--dist",  type=str,                     help="distance", default="0")
@click.option("--neg",  is_flag=True,                  help="Search for complemented spec")
def query(catalog, spec, dist, neg):
	""" Query the catalog for a specific lut implementation """
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	cache = ALSCatalogCache(catalog)
	x = cache.get_lut_at_dist(spec if not neg else negate(spec), dist)
	if x is None:
		print(f"{spec}@{dist} not in the catalog cache")
	else:
		print(x)


@click.command("stats")
@click.option("--catalog",       type=str, required = True, help="specify the path for the LUT-catalog cache file")
@click.option("--gates",                   is_flag = True,  help="histogram of functions w.r.t. the number of AIG nodes")
@click.option("--power-gates",             is_flag = True,  help="box-and-whiskers plot of switching activity w.r.t. the number of AIG nodes")
@click.option("--power-truth",             is_flag = True,  help="box-and-whiskers plot of switching activity w.r.t. the truth-density")
@click.option("--power-truth-k", type=int,                  help="box-and-whiskers plot of switching activity w.r.t. the truth-density for k-luts", default = None)
def stats(catalog, gates, power_gates, power_truth, power_truth_k):
	""" Compute statistics on a given catalog """
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	if gates:
		gates_histogram(catalog)
	if power_gates:
		power_gates_boxplot(catalog)
	if power_truth:
		power_truth_boxplot(catalog)
	if power_truth_k is not None:
		power_truth_k_boxplot(power_truth_k)


cli.add_command(plot)
cli.add_command(es_synth)
cli.add_command(als)
cli.add_command(rewrite)
cli.add_command(clean)
cli.add_command(expand)
cli.add_command(query)
cli.add_command(stats)

if __name__ == '__main__':
	if git_updater():
		os.execv(sys.argv[0], sys.argv)
	else:
		cli()
