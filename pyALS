#!/usr/bin/python3
"""
Copyright 2021-2022 Salvatore Barone <salvatore.barone@unina.it>

This is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 3 of the License, or any later version.

This is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for
more details.

You should have received a copy of the GNU General Public License along with
RMEncoder; if not, write to the Free Software Foundation, Inc., 51 Franklin
Street, Fifth Floor, Boston, MA 02110-1301, USA.
"""

import sys, os, click, git
from pyosys import libyosys as ys
from distutils.dir_util import mkpath
from src.ALSCatalog import *
from src.MOP import *
from src.ALSRewriter import *
from src.stats import *
from src.ConfigParser import *


def git_updater():
	try:
		dir_path = os.path.dirname(os.path.realpath(__file__))
		repo = git.Repo(dir_path)
		repo.remotes.origin.fetch()
		local_head = repo.heads[0].commit
		remote_head = repo.remotes.origin.refs[0].commit
		print(f"Remote HEAD: {remote_head}, local HEAD: {local_head}")
		if remote_head != local_head:
			print("Updating the tool...")
			repo.remotes.origin.pull()
			for submodule in repo.submodules:
				submodule.update(init = True, recursive = True)
			return True
		return False
	except git.exc.GitCommandError as e:
		print(e)
		print("\n*** Ensure you have access to the internet! ***\n")
		exit()


def read_source(source_file, top_module, ys_design):
	if isinstance(source_file, (list, tuple)):
		for s in source_file:
			read_single_source(s, ys_design)
	else:
		read_single_source(source_file, ys_design)
	ys.run_pass(f"hierarchy -check -top {top_module}", ys_design)


def read_single_source(source_file, ys_design):
	check_for_file(source_file)
	name, extension = os.path.splitext(source_file)
	if extension == ".vhd":
		#ys.run_pass(f"ghdl {source_file} -e {top_module}", ys_design)
		ys.run_pass(f"ghdl -a {source_file}", ys_design)
	elif extension == ".sv":
		ys.run_pass(f"read_verilog -sv {source_file}", ys_design)
	elif extension == ".v":
		ys.run_pass(f"read_verilog {source_file}", ys_design)
	elif extension == ".blif":
		ys.run_pass(f"read_blif {source_file}", ys_design)
	else:
		raise RuntimeError(f"Error parsing source file {source_file}: unknown extension ({extension})")


def synth_design(ys_design, top_module, cut_size, design_name_save="original"):
	ys.run_pass(f"prep; flatten; splitnets -ports; synth -top {top_module}; flatten; clean -purge; synth -lut {str(cut_size)}", ys_design)
	ys.run_pass(f"tee -q design -save {design_name_save}", ys_design)


def plot_labels(error_conf, hw_conf):
	error_labels = {
		ErrorConfig.Metric.EPROB: "Error probability",
		ErrorConfig.Metric.AWCE: "AWCE",
		ErrorConfig.Metric.MAE: "MAE",
		ErrorConfig.Metric.WRE: "WRE",
		ErrorConfig.Metric.MRE: "MRE",
		ErrorConfig.Metric.MSE: "MSE",
		ErrorConfig.Metric.MED: "MED",
		ErrorConfig.Metric.MRED: "MRED"
	}
	hw_labels = {
		HwConfig.Metric.GATES : "#AIG nodes",
		HwConfig.Metric.DEPTH : "AIG depth",
		HwConfig.Metric.SWITCHING : "Switching activity"
	}
	return [ error_labels[error_conf.metric] ] + [ hw_labels[m] for m in hw_conf.metrics ] if error_conf.builtin_metric else ["Error"] + [ hw_labels[m] for m in hw_conf.metrics ]


def check_for_optional_file(file_name):
	if file_name is not None and not os.path.exists(file_name):
		print(f"{file_name}: no such file.")
		exit()


def check_for_file(file_name):
	if not os.path.exists(file_name):
		print(f"{file_name}: no such file.")
		exit()


@click.group()
def cli():
	pass


@click.command("plot")
@click.option("--source",  type=str, required=True, help="specify the input HDL source file", multiple=True)
@click.option("--top",     type=str, required=True, help="specify the top-module name")
@click.option("--lut",     type=str, required=True, help="specify the LUT size")
@click.option("--output",  type=str, required=True, help="Output file.")
def plot(source, top, lut, output):
	"""
	Draws a k-LUT map of the given circuit
	"""
	design = ys.Design()
	ys.run_pass("plugin -i ghdl", design)
	print("GHDL plugin loaded successfully")
	read_source(source, top, design)
	print(f"{source} read successfully")
	synth_design(design, top, lut)
	print(f"{lut}-LUT synthesis successful")
	graph = ALSGraph(design)
	print(f"Graph generation completed")
	graph.save(output)


@click.command("es")
@click.option("--config",  required = True, type=str, help="path of the configuration file")
def es_synth(config):
	"""
	Performs the catalog-based AIG-rewriting workflow until catalog generation, i.e., including cut enumeration, and
	exact synthesis of approximate cuts, but it performs neither the design space exploration phase not the rewriting.
	"""
	check_for_file(config)
	configuration = ConfigParser(config, "es")
	check_for_file(configuration.lut_cache)
	design = ys.Design()
	ys.run_pass("plugin -i ghdl", design)
	print("GHDL plugin loaded successfully")
	read_source(configuration.source_hdl, configuration.top_module, design)
	print(f"{configuration.source_hdl} read successfully")
	synth_design(design, configuration.top_module, configuration.als_conf.cut_size)
	print(f"{configuration.als_conf.cut_size}-LUT synthesis successful")
	print(f"Performing catalog generation using {cpu_count()} threads. Please wait patiently. This may take time.")
	ALSCatalog(configuration.lut_cache, configuration.als_conf.solver).generate_catalog(design, configuration.als_conf.timeout)
	print("Done!")


@click.command("dataset")
@click.option("--source",  type=str, multiple=True, help="specify the input HDL source file")
@click.option("--top",     type=str, required=True, help="specify the top-module name")
@click.option("--output",  type=str, required=True, help="Output file.")
def dataset(source, top, output):
	"""
	Draws a k-LUT map of the given circuit
	"""
	design = ys.Design()
	ys.run_pass("plugin -i ghdl", design)
	print("GHDL plugin loaded successfully")
	read_source(source, top, design)
	print(f"{source} read successfully")
	synth_design(design, top, "4")
	print(f"Synthesis successful")
	graph = ALSGraph(design)
	print(f"Graph generation completed")
	PI = graph.get_pi()
	original_stdout = sys.stdout
	row_format = ",".join([i["name"] for i in PI])
	with open(output, "w") as file:
		sys.stdout = file
		print(row_format)
	sys.stdout = original_stdout


@click.command("als")
@click.option("--config",  type=str, help="path of the configuration file")
@click.option("--improve", type=str, help="Path of the file containing results from previous runs to be improved (JSON file)", default=None)
def als(config, improve):
	"""
	Performs the full catalog-based AIG-rewriting workflow, including cut enumeration, exact synthesis of approximate
	cuts, design space exploration and rewriting.
	"""
	check_for_file(config)
	configuration = ConfigParser(config, "als")
	check_for_file(configuration.lut_cache)
	check_for_optional_file(improve)
	if configuration.error_conf.dataset is not None:
		check_for_file(configuration.error_conf.dataset)
	if configuration.output_dir != ".":
		mkpath(configuration.output_dir)
	design = ys.Design()
	ys.run_pass("plugin -i ghdl", design)
	print("GHDL plugin loaded successfully")
	read_source(configuration.source_hdl, configuration.top_module, design)
	print(f"{configuration.source_hdl} read successfully")
	synth_design(design, configuration.top_module, configuration.als_conf.cut_size)
	print(f"{configuration.als_conf.cut_size}-LUT synthesis successful")
	graph = ALSGraph(design)
	print(f"Graph generation completed")
	if configuration.error_conf.weights is not None and len(configuration.error_conf.weights) != 0:
		configuration.error_conf.validate_weights(graph)
		print("Output-weight parsing completed successfully")
	print(f"Performing catalog generation using {cpu_count()} threads. Please wait patiently. This may take time.")
	lut_catalog = ALSCatalog(configuration.lut_cache, configuration.als_conf.solver).generate_catalog(design, configuration.als_conf.timeout)
	print(f"Performing AMOSA heuristic using {cpu_count()} threads. Please wait patiently. This may take time.")
	problem = MOP(configuration.top_module, graph, lut_catalog, configuration.error_conf, configuration.hw_conf)
	optimizer = AMOSA(configuration.amosa_conf)
	optimizer.run(problem, improve)
	hours = int(optimizer.duration / 3600)
	minutes = int((optimizer.duration - hours * 3600) / 60)
	print(f"Took {hours} hours, {minutes} minutes")
	optimizer.save_results(problem, f"{configuration.output_dir}/report.csv")
	optimizer.archive_to_json(f"{configuration.output_dir}/final_archive.json")
	optimizer.plot_pareto(problem, f"{configuration.output_dir}/pareto_front.pdf", "", plot_labels(configuration.error_conf, configuration.hw_conf))
	pareto_set = optimizer.pareto_set()
	print(f"Performing AIG-rewriting.")
	rewriter = ALSRewriter(graph, lut_catalog)
	for c, n in zip(pareto_set, range(len(pareto_set))):
		hdl_file_name = f"{configuration.output_dir}/variant_{n:05d}"
		rewriter.rewrite_and_save("original", c, hdl_file_name)
		print(f"{hdl_file_name} written successfully")
	print(f"All done! Take a look at {configuration.output_dir}!")


@click.command('clean')
@click.option('--catalog', type = str, required = True, help = 'Path of the LUT-catalog cache file')
def clean(catalog):
	"""Performs a sanity check of the catalog """
	check_for_file(catalog)
	cache = ALSCatalogCache(catalog)
	count = 0
	for s in cache.get_all_exact_luts():
		exact_synth_spec, exact_S, exact_P, exact_out_p, exact_out, exact_depth = s
		gates = len(exact_S[0])
		distance = 0
		for spec in cache.get_approx_luts(exact_synth_spec):
			ax_synth_spec, ax_S, ax_P, ax_out_p, ax_out, ax_depth = spec
			dist = hamming(exact_synth_spec, ax_synth_spec)
			if len(ax_S[0]) >= gates or dist < distance:
				cache.del_lut(exact_synth_spec, dist)
				count += 1
			else:
				gates = len(ax_S[0])
				distance = dist
	# search for complemented specifications
	for x in cache.get_all_exact_luts():
		x_synth_spec, _, _, _, _, _ = x
		for y in cache.get_all_exact_luts():
			y_synth_spec, _, _, _, _, _ = y
			if x_synth_spec == negate(y_synth_spec):
				cache.del_spec(y_synth_spec)
				count += 1
	print(f"Deleted {count} instances")


@click.command("expand")
@click.option('--catalog', type = str, required = True, help = 'Path of the LUT-catalog cache file')
def expand(catalog):
	""" Attempts catalog expansion """
	check_for_file(catalog)
	cache = ALSCatalogCache(catalog)
	# try to complete any incomplete path in the catalog
	luts_to_be_synthesized = set()
	for x in cache.get_all_exact_luts():
		ex_spec, ex_dist, ex_synth_spec, ex_S, ex_P, ex_p, ex_out, ex_depth = x
		axspect = cache.get_approx_luts(ex_spec)
		ax_synth_spec, ax_S, ax_P, ax_out_p, ax_out, ax_depth = axspect[-1]
		gates = len(ax_S[0])
		distance = hamming(ex_spec, ax_synth_spec)
		if gates > 0:
			print(f"Incomplete catalog found for spec {ex_spec}. Synthesis will start from Hamming distance {distance + 1}")
			luts_to_be_synthesized.add((ex_spec, gates, distance + 1))
	luts_to_be_synthesized = list(luts_to_be_synthesized)
	random.shuffle(luts_to_be_synthesized)
	luts_sets = list_partitioning(luts_to_be_synthesized, cpu_count())
	args = [[catalog, lut_set, 60000, ALSConfig.Solver.Boolector] for lut_set in luts_sets]
	with Pool(cpu_count()) as pool:
		ax_added = pool.starmap(synthesize_at_dist, args)
	print(f"{sum(ax_added)} new approximate LUTs inserted in the catalog cache while attempting catalog completion")
	# for each lut in the catalog, we add the synthesized approximate lut as exact lut at distance 0, if they do not belong to the catalog
	# this improves the hit-rate for exact luts
	exact_added = 0
	luts_to_be_synthesized = set()
	for x in cache.get_all_luts():
		x_spec, x_dist, x_synth_spec, x_S, x_P, x_p, x_out, x_depth = x
		if cache.get_lut_at_dist(x_synth_spec, 0) is None:
			cache.add_lut(x_synth_spec, 0, x_synth_spec, x_S, x_P, x_p, x_out, x_depth)
			if x_synth_spec not in luts_to_be_synthesized and negate(x_synth_spec) not in luts_to_be_synthesized:
				luts_to_be_synthesized.add(x_synth_spec)
			exact_added += 1
	print(f"{exact_added} new exact LUTs inserted in the catalog cache")
	luts_to_be_synthesized = list(luts_to_be_synthesized)
	random.shuffle(luts_to_be_synthesized)
	luts_sets = list_partitioning(luts_to_be_synthesized, cpu_count())
	args = [[catalog, lut_set, 60000, ALSConfig.Solver.Boolector] for lut_set in luts_sets]
	with Pool(cpu_count()) as pool:
		ax_added = pool.starmap(synthesize, args)
	print(f"{sum(ax_added)} new approximate LUTs inserted in the catalog cache")


@click.command("query")
@click.option("--catalog", type=str,  required = True, help="specify the path for the LUT-catalog cache file")
@click.option("--spec",  type=str,    required = True, help="LUT specification to search")
@click.option("--dist",  type=str,                     help="distance", default="0")
@click.option("--neg",  is_flag=True,                  help="Search for complemented spec")
def query(catalog, spec, dist, neg):
	""" Query the catalog for a specific lut implementation """
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	cache = ALSCatalogCache(catalog)
	x = cache.get_lut_at_dist(spec if not neg else negate(spec), dist)
	if x is None:
		print(f"{spec}@{dist} not in the catalog cache")
	else:
		print(x)


@click.command("stats")
@click.option("--catalog",       type=str, required = True, help="specify the path for the LUT-catalog cache file")
@click.option("--gates",                   is_flag = True,  help="histogram of functions w.r.t. the number of AIG nodes")
@click.option("--power-gates",             is_flag = True,  help="box-and-whiskers plot of switching activity w.r.t. the number of AIG nodes")
@click.option("--power-truth",             is_flag = True,  help="box-and-whiskers plot of switching activity w.r.t. the truth-density")
@click.option("--power-truth-k", type=int,                  help="box-and-whiskers plot of switching activity w.r.t. the truth-density for k-luts", default = None)
def stats(catalog, gates, power_gates, power_truth, power_truth_k):
	""" Compute statistics on a given catalog """
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	if gates:
		gates_histogram(catalog)
	if power_gates:
		power_gates_boxplot(catalog)
	if power_truth:
		power_truth_boxplot(catalog)
	if power_truth_k is not None:
		power_truth_k_boxplot(power_truth_k)


cli.add_command(dataset)
cli.add_command(plot)
cli.add_command(es_synth)
cli.add_command(als)
cli.add_command(clean)
cli.add_command(expand)
cli.add_command(query)
cli.add_command(stats)


if __name__ == '__main__':
	if git_updater():
		os.execv(sys.argv[0], sys.argv)
	else:
		cli()
