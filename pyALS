#!/usr/bin/python3
"""
Copyright 2021-2022 Salvatore Barone <salvatore.barone@unina.it>

This is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 3 of the License, or any later version.

This is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for
more details.

You should have received a copy of the GNU General Public License along with
RMEncoder; if not, write to the Free Software Foundation, Inc., 51 Franklin
Street, Fifth Floor, Boston, MA 02110-1301, USA.
"""

import sys, os, click, git, shutil
from distutils.dir_util import mkpath
from src.ALSCatalog import *
from src.MOP import *
from src.ALSRewriter import *
from src.stats import *
from src.ConfigParser import *


def git_updater():
	try:
		dir_path = os.path.dirname(os.path.realpath(__file__))
		repo = git.Repo(dir_path)
		repo.remotes.origin.fetch()
		local_head = repo.heads[0].commit
		remote_head = repo.remotes.origin.refs[0].commit
		if remote_head != local_head:
			print("Updating the tool...")
			repo.remotes.origin.pull()
			for submodule in repo.submodules:
				submodule.update(init = True, recursive = True)
			return True
		return False
	except git.exc.GitCommandError as e:
		print(e)
		print("\n*** Ensure you have access to the internet! ***\n")
		exit()


def rm_old_implementation(output_directory):
	for file in os.listdir(output_directory):
		if file.endswith('.v'):
			print(f"Removing old source-file {output_directory}/{file}")
			os.remove(f"{output_directory}/{file}")


@click.group()
def cli():
	pass


@click.command("elaborate")
@click.option("--source",  type=str, required=True, help="specify the input HDL source file", multiple=True)
@click.option("--top",     type=str, required=True, help="specify the top-module name")
@click.option("--lut",     type=str, required=True, help="specify the LUT size")
@click.option("--output",  type=str, required=True, help="Output file.")
def elaborate(source, top, lut, output):
	"""
	Draws a k-LUT map of the given circuit
	"""
	helper = YosysHelper()
	helper.load_ghdl()
	helper.read_sources(source, top)
	helper.prep_design(lut)
	graph = ALSGraph(helper.design)
	print(f"Graph generation completed")
	graph.save(output)


@click.command("es")
@click.option("--config",  required = True, type=str, help="path of the configuration file")
def es_synth(config):
	"""
	Performs the catalog-based AIG-rewriting workflow until catalog generation, i.e., including cut enumeration, and
	exact synthesis of approximate cuts, but it performs neither the design space exploration phase not the rewriting.
	"""
	check_for_file(config)
	configuration = ConfigParser(config, "es")
	check_for_file(configuration.lut_cache)
	helper = YosysHelper()
	helper.load_ghdl()
	helper.read_sources(configuration.source_hdl, configuration.top_module)
	helper.prep_design(configuration.als_conf.cut_size)
	luts_set = helper.get_luts_set()
	print(f"Performing catalog generation using {cpu_count()} threads. Please wait patiently. This may take time.")
	ALSCatalog(configuration.lut_cache, configuration.als_conf.solver).generate_catalog(luts_set, configuration.als_conf.timeout)
	print("Done!")


@click.command("als")
@click.option("--config",  type=str, required = True, help="path of the configuration file")
@click.option("--store", type=str, help = "Store the random vectors adopted for error estimation on file, for further use.", default = None)
@click.option("--improve", type=str, help="Path of the file containing results from previous runs to be improved (JSON file)", default=None)
def als(config, store, improve):
	"""
	Performs the full catalog-based AIG-rewriting workflow, including cut enumeration, exact synthesis of approximate
	cuts, design space exploration and rewriting.
	"""
	check_for_file(config)
	configuration = ConfigParser(config, "als")
	check_for_file(configuration.lut_cache)
	check_for_optional_file(improve)
	if configuration.error_conf.dataset is not None:
		check_for_file(configuration.error_conf.dataset)
	if configuration.output_dir != ".":
		mkpath(configuration.output_dir)
	if store is None:
		count = 1
		while os.path.exists(os.path.realpath(f"{configuration.output_dir}/random_dataset_{count:05d}.json")):
			count += 1
		store = os.path.realpath(f"{configuration.output_dir}/random_dataset_{count:05d}.json")
	helper = YosysHelper()
	helper.load_ghdl()
	helper.read_sources(configuration.source_hdl, configuration.top_module)
	helper.prep_design(configuration.als_conf.cut_size)
	luts_set = helper.get_luts_set()
	graph = ALSGraph(helper.design)
	print(f"Graph generation completed")
	helper.save_design("original")
	if configuration.error_conf.weights is not None and len(configuration.error_conf.weights) != 0:
		configuration.error_conf.validate_weights(graph)
		print("Output-weight parsing completed successfully")
	print(f"Performing catalog generation using {cpu_count()} threads. Please wait patiently. This may take time.")
	lut_catalog = ALSCatalog(configuration.lut_cache, configuration.als_conf.solver).generate_catalog(luts_set, configuration.als_conf.timeout)
	print(f"Performing AMOSA heuristic using {cpu_count()} threads. Please wait patiently. This may take time.")
	problem = MOP(configuration.top_module, graph, lut_catalog, configuration.error_conf, configuration.hw_conf, store)
	optimizer = AMOSA(configuration.amosa_conf)
	optimizer.hill_climb_checkpoint_file = f"{configuration.output_dir}/{optimizer.hill_climb_checkpoint_file}"
	optimizer.minimize_checkpoint_file = f"{configuration.output_dir}/{optimizer.minimize_checkpoint_file}"
	optimizer.cache_dir = f"{configuration.output_dir}/{optimizer.cache_dir}"
	optimizer.run(problem, improve)
	hours = int(optimizer.duration / 3600)
	minutes = int((optimizer.duration - hours * 3600) / 60)
	print(f"Took {hours} hours, {minutes} minutes")
	print(f"Cache hits: {problem.cache_hits} over {problem.total_calls} evaluations.")
	print(f"{len(problem.cache)} cache entries collected")
	optimizer.archive_to_json(f"{configuration.output_dir}/final_archive.json")
	fitness_labels = problem.plot_labels()
	optimizer.archive_to_csv(problem, f"{configuration.output_dir}/final_archive.csv", fitness_labels)
	optimizer.plot_pareto(problem, f"{configuration.output_dir}/pareto_front.pdf", configuration.top_module, fitness_labels)
	pareto_set = optimizer.pareto_set()
	rm_old_implementation(configuration.output_dir)
	print(f"Performing AIG-rewriting.")
	rewriter = ALSRewriter(helper, problem)
	rewriter.generate_hdl(pareto_set, configuration.output_dir)
	print(f"All done! Take a look at {configuration.output_dir}!")


@click.command('generate')
@click.option("--config",  type=str, help="path of the configuration file")
def generate(config):
	"""
	Performs the rewriting step of the catalog-based AIG-rewriting workflow, starting from the results of a previous run of the "als" command
	"""
	check_for_file(config)
	configuration = ConfigParser(config, "als")
	check_for_file(configuration.lut_cache)
	if configuration.error_conf.dataset is not None:
		check_for_file(configuration.error_conf.dataset)
	if configuration.output_dir != ".":
		mkpath(configuration.output_dir)
	check_for_file(f"{configuration.output_dir}/final_archive.json")
	helper = YosysHelper()
	helper.load_ghdl()
	helper.read_sources(configuration.source_hdl, configuration.top_module)
	helper.prep_design(configuration.als_conf.cut_size)
	luts_set = helper.get_luts_set()
	graph = ALSGraph(helper.design)
	print(f"Graph generation completed")
	helper.save_design("original")
	if configuration.error_conf.weights is not None and len(configuration.error_conf.weights) != 0:
		configuration.error_conf.validate_weights(graph)
		print("Output-weight parsing completed successfully")
	print(f"Performing catalog generation using {cpu_count()} threads. Please wait patiently. This may take time.")
	lut_catalog = ALSCatalog(configuration.lut_cache, configuration.als_conf.solver).generate_catalog(luts_set, configuration.als_conf.timeout)
	print(f"Reading the Pareto front.")
	problem = MOP(configuration.top_module, graph, lut_catalog, configuration.error_conf, configuration.hw_conf, None)
	optimizer = AMOSA(configuration.amosa_conf)
	optimizer.read_final_archive_from_json(problem, f"{configuration.output_dir}/final_archive.json")
	optimizer.plot_pareto(problem, f"{configuration.output_dir}/pareto_front.pdf", "", problem.plot_labels())
	pareto_set = optimizer.pareto_set()
	rm_old_implementation(configuration.output_dir)
	print(f"Performing AIG-rewriting.")
	rewriter = ALSRewriter(helper, problem)
	rewriter.generate_hdl(pareto_set, configuration.output_dir)
	print(f"All done! Take a look at {configuration.output_dir}!")


@click.command("template")
@click.option("--source",  type=str, multiple=True, help="specify the input HDL source file")
@click.option("--top",     type=str, required=True, help="specify the top-module name")
@click.option("--output",  type=str, required=True, help="Output file.")
def template(source, top, output):
	"""
	Generates a CSV file for specifying the input dataset to be used for error assessment
	"""
	helper = YosysHelper()
	helper.load_ghdl()
	helper.read_sources(source, top)
	helper.prep_design(4)
	graph = ALSGraph(helper.design)
	print(f"Graph generation completed")
	PI = graph.get_pi()
	original_stdout = sys.stdout
	row_format = ",".join([i["name"] for i in PI])
	with open(output, "w") as file:
		sys.stdout = file
		print(row_format)
	sys.stdout = original_stdout


@click.command("randomsplit")
@click.option("--source",  type=str, multiple=True, help="specify the input HDL source file")
@click.option("--top",     type=str, required=True, help="specify the top-module name")
@click.option("--splits",  type=int, required=True, help="amount of dataset partitions")
@click.option("--outputdir",  type=str, required=True, help="output directory")
def randomsplit(source, top, splits, outputdir):
	"""
	Split the input-set in N partitions, using random sampling without repetitions.
	"""
	mkpath(outputdir)
	helper = YosysHelper()
	helper.load_ghdl()
	helper.read_sources(source, top)
	helper.prep_design(4)
	graph = ALSGraph(helper.design)
	print(f"Graph generation completed")
	PI = graph.get_pi()
	PI = [i["name"] for i in PI]
	permutations = [list(i) for i in itertools.product([False, True], repeat = len(PI))]
	assignments = [{i: p for i, p in zip(PI, perm)} for perm in permutations]
	random.shuffle(assignments)
	splitsize = len(assignments) // splits
	for i in range(splits):
		original_stdout = sys.stdout
		with open(f"{outputdir}/split_{i}.csv", "w") as file:
			sys.stdout = file
			print(",".join(PI))
			for r in range(i*splitsize, (i+1)*splitsize):
				print(",".join(["1" if assignments[r][p] else "0" for p in PI]))
		sys.stdout = original_stdout
	print("Dataset generation completed")


@click.command('clean')
@click.option('--catalog', type = str, required = True, help = 'Path of the LUT-catalog cache file')
def clean(catalog):
	"""Performs a sanity check of the catalog """
	check_for_file(catalog)
	cache = ALSCatalogCache(catalog)
	count = 0
	for s in cache.get_all_exact_luts():
		exact_synth_spec, exact_S, exact_P, exact_out_p, exact_out, exact_depth = s
		gates = len(exact_S[0])
		distance = 0
		for spec in cache.get_approx_luts(exact_synth_spec):
			ax_synth_spec, ax_S, ax_P, ax_out_p, ax_out, ax_depth = spec
			dist = hamming(exact_synth_spec, ax_synth_spec)
			if len(ax_S[0]) >= gates or dist < distance:
				cache.del_lut(exact_synth_spec, dist)
				count += 1
			else:
				gates = len(ax_S[0])
				distance = dist
	# search for complemented specifications
	for x in cache.get_all_exact_luts():
		x_synth_spec, _, _, _, _, _ = x
		for y in cache.get_all_exact_luts():
			y_synth_spec, _, _, _, _, _ = y
			if x_synth_spec == negate(y_synth_spec):
				cache.del_spec(y_synth_spec)
				count += 1
	print(f"Deleted {count} instances")


@click.command("expand")
@click.option('--catalog', type = str, required = True, help = 'Path of the LUT-catalog cache file')
def expand(catalog):
	""" Attempts catalog expansion """
	check_for_file(catalog)
	cache = ALSCatalogCache(catalog)
	# try to complete any incomplete path in the catalog
	luts_to_be_synthesized = set()
	for x in cache.get_all_exact_luts():
		ex_spec, ex_dist, ex_synth_spec, ex_S, ex_P, ex_p, ex_out, ex_depth = x
		axspect = cache.get_approx_luts(ex_spec)
		ax_synth_spec, ax_S, ax_P, ax_out_p, ax_out, ax_depth = axspect[-1]
		gates = len(ax_S[0])
		distance = hamming(ex_spec, ax_synth_spec)
		if gates > 0:
			print(f"Incomplete catalog found for spec {ex_spec}. Synthesis will start from Hamming distance {distance + 1}")
			luts_to_be_synthesized.add((ex_spec, gates, distance + 1))
	luts_to_be_synthesized = list(luts_to_be_synthesized)
	random.shuffle(luts_to_be_synthesized)
	luts_sets = list_partitioning(luts_to_be_synthesized, cpu_count())
	args = [[catalog, lut_set, 60000, ALSConfig.Solver.Boolector] for lut_set in luts_sets]
	with Pool(cpu_count()) as pool:
		ax_added = pool.starmap(synthesize_at_dist, args)
	print(f"{sum(ax_added)} new approximate LUTs inserted in the catalog cache while attempting catalog completion")
	# for each lut in the catalog, we add the synthesized approximate lut as exact lut at distance 0, if they do not belong to the catalog
	# this improves the hit-rate for exact luts
	exact_added = 0
	luts_to_be_synthesized = set()
	for x in cache.get_all_luts():
		x_spec, x_dist, x_synth_spec, x_S, x_P, x_p, x_out, x_depth = x
		if cache.get_lut_at_dist(x_synth_spec, 0) is None:
			cache.add_lut(x_synth_spec, 0, x_synth_spec, x_S, x_P, x_p, x_out, x_depth)
			if x_synth_spec not in luts_to_be_synthesized and negate(x_synth_spec) not in luts_to_be_synthesized:
				luts_to_be_synthesized.add(x_synth_spec)
			exact_added += 1
	print(f"{exact_added} new exact LUTs inserted in the catalog cache")
	luts_to_be_synthesized = list(luts_to_be_synthesized)
	random.shuffle(luts_to_be_synthesized)
	luts_sets = list_partitioning(luts_to_be_synthesized, cpu_count())
	args = [[catalog, lut_set, 60000, ALSConfig.Solver.Boolector] for lut_set in luts_sets]
	with Pool(cpu_count()) as pool:
		ax_added = pool.starmap(synthesize, args)
	print(f"{sum(ax_added)} new approximate LUTs inserted in the catalog cache")


@click.command("query")
@click.option("--catalog", type=str,  required = True, help="specify the path for the LUT-catalog cache file")
@click.option("--spec",  type=str,    required = True, help="LUT specification to search")
@click.option("--dist",  type=str,                     help="distance", default="0")
@click.option("--neg",  is_flag=True,                  help="Search for complemented spec")
def query(catalog, spec, dist, neg):
	""" Query the catalog for a specific lut implementation """
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	cache = ALSCatalogCache(catalog)
	x = cache.get_lut_at_dist(spec if not neg else negate(spec), dist)
	if x is None:
		print(f"{spec}@{dist} not in the catalog cache")
	else:
		print(x)


@click.command("stats")
@click.option("--catalog",       type=str, required = True, help="specify the path for the LUT-catalog cache file")
@click.option("--gates",                   is_flag = True,  help="histogram of functions w.r.t. the number of AIG nodes")
@click.option("--power-gates",             is_flag = True,  help="box-and-whiskers plot of switching activity w.r.t. the number of AIG nodes")
@click.option("--power-truth",             is_flag = True,  help="box-and-whiskers plot of switching activity w.r.t. the truth-density")
@click.option("--power-truth-k", type=int,                  help="box-and-whiskers plot of switching activity w.r.t. the truth-density for k-luts", default = None)
def stats(catalog, gates, power_gates, power_truth, power_truth_k):
	""" Compute statistics on a given catalog """
	if not os.path.exists(catalog):
		print(f"{catalog}: no such file.")
		exit()
	if gates:
		gates_histogram(catalog)
	if power_gates:
		power_gates_boxplot(catalog)
	if power_truth:
		power_truth_boxplot(catalog)
	if power_truth_k is not None:
		power_truth_k_boxplot(power_truth_k)


cli.add_command(randomsplit)
cli.add_command(template)
cli.add_command(elaborate)
cli.add_command(es_synth)
cli.add_command(als)
cli.add_command(generate)
cli.add_command(clean)
cli.add_command(expand)
cli.add_command(query)
cli.add_command(stats)


if __name__ == '__main__':
	if git_updater():
		os.execv(sys.argv[0], sys.argv)
	else:
		cli()
